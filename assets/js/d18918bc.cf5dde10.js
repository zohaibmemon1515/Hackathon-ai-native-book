"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[2605],{1335:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"simulation-to-real-world/chapter1/lesson2","title":"Techniques to Bridge the Sim2Real Gap","description":"Learning Objectives","source":"@site/docs/simulation-to-real-world/chapter1/lesson2.md","sourceDirName":"simulation-to-real-world/chapter1","slug":"/simulation-to-real-world/chapter1/lesson2","permalink":"/Hackathon-ai-native-book/book/docs/simulation-to-real-world/chapter1/lesson2","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/simulation-to-real-world/chapter1/lesson2.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Techniques to Bridge the Sim2Real Gap","sidebar_position":2},"sidebar":"tutorialSidebar","previous":{"title":"Understanding the Sim2Real Gap","permalink":"/Hackathon-ai-native-book/book/docs/simulation-to-real-world/chapter1/lesson1"},"next":{"title":"Validating Simulation Models with Real-World Data","permalink":"/Hackathon-ai-native-book/book/docs/simulation-to-real-world/chapter1/lesson3"}}');var o=n(4848),t=n(8453);const r={title:"Techniques to Bridge the Sim2Real Gap",sidebar_position:2},s=void 0,l={},d=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Concept Explanation",id:"concept-explanation",level:2},{value:"Real-World Examples",id:"real-world-examples",level:2},{value:"Mathematical or technical breakdown",id:"mathematical-or-technical-breakdown",level:2},{value:"Mini-Project",id:"mini-project",level:2},{value:"Summary",id:"summary",level:2},{value:"APA-style references",id:"apa-style-references",level:2}];function c(e){const i={code:"code",em:"em",h2:"h2",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(i.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"Learn about various techniques used to bridge the sim-to-real gap."}),"\n",(0,o.jsx)(i.li,{children:"Understand the principles of domain randomization and domain adaptation."}),"\n",(0,o.jsx)(i.li,{children:"Explore system identification and residual learning as sim-to-real strategies."}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"concept-explanation",children:"Concept Explanation"}),"\n",(0,o.jsxs)(i.p,{children:["Bridging the ",(0,o.jsx)(i.strong,{children:"sim-to-real gap"})," is a critical area of research and development in robotics. Various techniques have emerged to mitigate the discrepancies between simulation and reality, allowing policies and models trained in simulation to perform effectively on physical robots."]}),"\n",(0,o.jsx)(i.p,{children:"Key techniques include:"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Domain Randomization (DR)"}),": Systematically varying simulation parameters (e.g., textures, lighting, object positions, physics properties, sensor noise) during training. The goal is to expose the agent to such a wide variety of simulated environments that the real world appears as just another (unseen) variation it has learned to handle."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Domain Adaptation (DA)"}),": Techniques that learn a mapping or alignment between features from the source domain (simulation) and the target domain (real world). This can involve unsupervised learning to make simulated features look more like real ones, or vice versa."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"System Identification"}),": Using real-world data to estimate or tune the parameters of the simulation model (e.g., friction coefficients, motor constants, sensor noise characteristics) to make the simulation more accurate."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Residual Learning"}),": Training a primary control policy in simulation and then learning a small, corrective (residual) policy directly on the real robot. This residual policy compensates for unmodeled dynamics and sim-to-real discrepancies."]}),"\n",(0,o.jsxs)(i.li,{children:[(0,o.jsx)(i.strong,{children:"Reinforcement Learning with Real-World Experience"}),": Fine-tuning a pre-trained simulated policy with a limited amount of real-world interaction, often using techniques like safe exploration or transfer learning."]}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"real-world-examples",children:"Real-World Examples"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"OpenAI's work on teaching a robotic hand to solve a Rubik's Cube uses aggressive domain randomization to achieve sim-to-real transfer."}),"\n",(0,o.jsx)(i.li,{children:"Autonomous driving companies use system identification to refine their vehicle dynamics models in simulation based on real driving data."}),"\n",(0,o.jsx)(i.li,{children:"Researchers use domain adaptation to make synthetic images generated in simulation appear more photorealistic, improving the performance of vision models on real camera data."}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"mathematical-or-technical-breakdown",children:"Mathematical or technical breakdown"}),"\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"Domain Randomization"}),": If ",(0,o.jsx)(i.code,{children:"P_sim(x, \u03b8_rand)"})," is the distribution of observations in a randomized simulation, where ",(0,o.jsx)(i.code,{children:"\u03b8_rand"})," are the randomized parameters, the objective is to make ",(0,o.jsx)(i.code,{children:"P_real(x) \u2248 P_sim(x, \u03b8_rand)"})," so that a policy trained on ",(0,o.jsx)(i.code,{children:"P_sim"})," generalizes to ",(0,o.jsx)(i.code,{children:"P_real"}),"."]}),"\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"System Identification"}),": This can be framed as an optimization problem where ",(0,o.jsx)(i.code,{children:"min ||f_sim(\u03b8) - f_real||^2"}),", where ",(0,o.jsx)(i.code,{children:"f_sim"})," represents the simulated robot's behavior parameterized by ",(0,o.jsx)(i.code,{children:"\u03b8"}),", and ",(0,o.jsx)(i.code,{children:"f_real"})," is the observed behavior of the real robot."]}),"\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"Domain Adaptation"}),": Techniques often involve adversarial training, similar to Generative Adversarial Networks (GANs), where a discriminator tries to distinguish between features from the two domains, and a feature extractor tries to fool the discriminator, learning domain-invariant features."]}),"\n",(0,o.jsx)(i.h2,{id:"mini-project",children:"Mini-Project"}),"\n",(0,o.jsxs)(i.p,{children:[(0,o.jsx)(i.strong,{children:"Design a Domain Randomization Strategy (Conceptual)"}),":"]}),"\n",(0,o.jsxs)(i.ol,{children:["\n",(0,o.jsx)(i.li,{children:"Consider a robot learning to grasp a specific object (e.g., a mug) in a simulated environment."}),"\n",(0,o.jsxs)(i.li,{children:["List at least five parameters you could randomize during training to improve the sim-to-real transfer of the grasping policy. For each parameter, specify:","\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsx)(i.li,{children:"The parameter (e.g., mug color)."}),"\n",(0,o.jsx)(i.li,{children:"The range of randomization (e.g., random RGB values)."}),"\n",(0,o.jsx)(i.li,{children:"Why randomizing this parameter would help bridge the sim-to-real gap."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(i.li,{children:"Discuss how your randomized simulation environment would compare to training in a fixed, non-randomized simulation."}),"\n"]}),"\n",(0,o.jsx)(i.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(i.p,{children:"Bridging the sim-to-real gap is crucial for efficient robotics development. Techniques like domain randomization, domain adaptation, system identification, and residual learning offer powerful ways to ensure that AI models and control policies developed in simulation can reliably perform on physical robots."}),"\n",(0,o.jsx)(i.h2,{id:"apa-style-references",children:"APA-style references"}),"\n",(0,o.jsxs)(i.ul,{children:["\n",(0,o.jsxs)(i.li,{children:["Tobin, J., et al. (2017). Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World. ",(0,o.jsx)(i.em,{children:"IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)"}),"."]}),"\n",(0,o.jsxs)(i.li,{children:["Shridhar, M., et al. (2020). Learning to Manipulate Deformable Objects without Explicit Physics. ",(0,o.jsx)(i.em,{children:"Conference on Robot Learning (CoRL)"}),"."]}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,t.R)(),...e.components};return i?(0,o.jsx)(i,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>r,x:()=>s});var a=n(6540);const o={},t=a.createContext(o);function r(e){const i=a.useContext(t);return a.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function s(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),a.createElement(t.Provider,{value:i},e.children)}}}]);